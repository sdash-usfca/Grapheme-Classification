{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import albumentations\n",
    "import joblib\n",
    "import pretrainedmodels\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics\n",
    "\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms, utils, models, datasets\n",
    "from torchsummary import summary\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CSV_PATH = \"../data/train.csv\"\n",
    "STRATIFIED_CSV_PATH = \"../data/stratified_train.csv\"\n",
    "\n",
    "TRAIN_IMG_PATH = \"../train_images/\"\n",
    "COMBINED_IMAGE_PATH = \"../data/\"\n",
    "\n",
    "TRAIN = ['../data/train_image_data_0.parquet',\n",
    "         '../data/train_image_data_1.parquet',\n",
    "         '../data/train_image_data_2.parquet',\n",
    "         '../data/train_image_data_3.parquet']\n",
    "\n",
    "TEST_CSV_PATH = \"../data/test.csv\"\n",
    "\n",
    "FOLDS = 5 # Represents stratification folds\n",
    "EPOCHS = 50 # number of iterations for running the model\n",
    "TRAIN_BATCH_SIZE = 32 # batch size to train from train set\n",
    "VALIDATION_BATCH_SIZE = 32 # batch size to validate from validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stratified_df():\n",
    "    if os.path.exists(STRATIFIED_CSV_PATH):\n",
    "        return pd.read_csv(STRATIFIED_CSV_PATH)\n",
    "    else:\n",
    "        df = pd.read_csv(TRAIN_CSV_PATH)\n",
    "        print(df.shape)\n",
    "        #Only used for testing purposes\n",
    "        #df = df.sample(frac = 0.2, random_state=0)\n",
    "        \n",
    "        df.loc[:, 'kfold'] = -1\n",
    "        df = df.sample(frac=1).reset_index(drop=True)\n",
    "        x = df.image_id.values\n",
    "        y = df[['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']].values\n",
    "        mskf = MultilabelStratifiedKFold(n_splits=FOLDS)\n",
    "        \n",
    "        for fold, (trn_, val_) in enumerate(mskf.split(x, y)):\n",
    "            df.loc[val_, \"kfold\"] = fold\n",
    "\n",
    "        df.to_csv(STRATIFIED_CSV_PATH, index=False)\n",
    "        print(df.shape)\n",
    "        return df\n",
    "\n",
    "train_df = generate_stratified_df()\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphemeDataset(Dataset):\n",
    "    def __init__(self, label_df, augmentation=False):\n",
    "        self.label_df = label_df\n",
    "        if augmentation:\n",
    "            self.transforms = albumentations.Compose([\n",
    "                    albumentations.Resize(137, 236, always_apply=True),\n",
    "                    albumentations.ShiftScaleRotate(shift_limit=0.0625,\n",
    "                                               scale_limit=0.1, \n",
    "                                               rotate_limit=5,\n",
    "                                               p=0.9),\n",
    "                    albumentations.Normalize((0.485, 0.456, 0.406), \n",
    "                                             (0.229, 0.224, 0.225),\n",
    "                                             always_apply=True)\n",
    "                ])\n",
    "        else:\n",
    "            self.transforms = albumentations.Compose([\n",
    "                    albumentations.Resize(137, 236, always_apply=True),\n",
    "                    albumentations.Normalize((0.485, 0.456, 0.406), \n",
    "                                             (0.229, 0.224, 0.225),\n",
    "                                             always_apply=True)\n",
    "                ])\n",
    "            \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.label_df)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        label1 = torch.tensor(self.label_df.grapheme_root.values[idx], dtype=torch.long)\n",
    "        label2 = torch.tensor(self.label_df.vowel_diacritic.values[idx], dtype=torch.long)\n",
    "        label3 = torch.tensor(self.label_df.consonant_diacritic.values[idx], dtype=torch.long)\n",
    "        \n",
    "        image = joblib.load(TRAIN_IMG_PATH + self.label_df.image_id.values[idx] + \".pkl\")\n",
    "        image = image.reshape(137,236).astype(float)\n",
    "        image = Image.fromarray(image).convert(\"RGB\")\n",
    "        image = self.transforms(image=np.array(image))[\"image\"]\n",
    "            \n",
    "        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
    "        image = torch.tensor(image, dtype=torch.float) \n",
    "        return image,label1,label2,label3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50(nn.Module):\n",
    "    def __init__(self, pretrained):\n",
    "        super(ResNet50, self).__init__()\n",
    "        if pretrained is True:\n",
    "            self.model = pretrainedmodels.__dict__[\"resnet50\"](pretrained=\"imagenet\")\n",
    "        else:\n",
    "            self.model = pretrainedmodels.__dict__[\"resnet50\"](pretrained=None)\n",
    "        \n",
    "        # grapheme_root\n",
    "        self.l0 = nn.Linear(2048, 168)\n",
    "        \n",
    "        # vowel_diacritic\n",
    "        self.l1 = nn.Linear(2048, 11)\n",
    "        \n",
    "        # consonant_diacritic\n",
    "        self.l2 = nn.Linear(2048, 7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs, _, _, _ = x.shape\n",
    "        x = self.model.features(x)\n",
    "        x = F.adaptive_avg_pool2d(x, 1).reshape(bs, -1)\n",
    "        l0 = self.l0(x)\n",
    "        l1 = self.l1(x)\n",
    "        l2 = self.l2(x)\n",
    "        return l0, l1, l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model, optimizer, criterion, scheduler, \n",
    "              folds=5, epochs=20, train_batch_size=32, validation_batch_size=32):\n",
    "    \n",
    "    train_validate_df = generate_stratified_df()\n",
    "    best_acc = 0.0\n",
    "    train_losses = []\n",
    "    train_recalls = []\n",
    "    valid_losses = []\n",
    "    valid_recalls = []\n",
    "    final_train_outputs = final_train_targets = final_valid_outputs = final_valid_targets = None  \n",
    "    for fold in range(folds):\n",
    "        print('folds {}/{} '.format(fold+1,folds))\n",
    "        \n",
    "        train_df = train_validate_df[~train_validate_df.kfold.isin([fold])].reset_index(drop=True)\n",
    "        validate_df = train_validate_df[train_validate_df.kfold.isin([fold])].reset_index(drop=True)\n",
    "        \n",
    "        train_image = GraphemeDataset(train_df)\n",
    "        validation_image = GraphemeDataset(validate_df)\n",
    "        \n",
    "        train_loader = DataLoader(train_image, \n",
    "                batch_size=train_batch_size, shuffle=True, num_workers=4)\n",
    "        \n",
    "        validation_loader = DataLoader(validation_image,\n",
    "            batch_size=validation_batch_size, shuffle=True, num_workers=4)\n",
    "        \n",
    "\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            print('epochs {}/{} '.format(epoch+1,epochs))\n",
    "            validation_loss = 0.0\n",
    "            validation_acc = 0.0\n",
    "            \n",
    "            train_recall, train_loss, train_outputs, train_targets  = train_model(model, optimizer, criterion, train_image, train_loader)\n",
    "            train_losses.append(train_loss)\n",
    "            train_recalls.append(train_recall)\n",
    "            \n",
    "            valid_recall, valid_loss, valid_outputs, valid_targets = validate_model(model, optimizer, criterion, validation_image, validation_loader)\n",
    "            valid_losses.append(valid_loss)\n",
    "            valid_recalls.append(valid_recall)\n",
    "            \n",
    "            scheduler.step(valid_loss)\n",
    "\n",
    "            if train_recall > best_acc:\n",
    "                best_acc = train_recall\n",
    "                final_train_outputs, final_train_targets, final_valid_outputs, final_valid_targets = train_outputs, train_targets, valid_outputs, valid_targets\n",
    "                torch.save(model.state_dict(), \"Resnet50.pth\")\n",
    "        \n",
    "            print('epochs {}/{} completed'.format(epoch+1,epochs))\n",
    "            \n",
    "        print('folds {}/{} completed'.format(fold+1,folds))\n",
    "\n",
    "    return train_recalls, train_losses, valid_recalls, valid_losses, final_train_outputs, final_train_targets, final_valid_outputs, final_valid_targets  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, criterion, train_dataset, train_loader):\n",
    "    model.train(True)\n",
    "    train_acc = 0.0\n",
    "    train_loss = 0.0\n",
    "    final_outputs = []\n",
    "    final_targets = []\n",
    "    for idx, (inputs,labels1,labels2,labels3) in tqdm(\n",
    "        enumerate(train_loader), total=int(len(train_dataset)/train_loader.batch_size)):\n",
    "        inputs = inputs.to(device, dtype=torch.float)\n",
    "\n",
    "        labels1 = labels1.to(device, dtype=torch.long)\n",
    "        labels2 = labels2.to(device, dtype=torch.long)\n",
    "        labels3 = labels3.to(device, dtype=torch.long)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs1,outputs2,outputs3 = model(inputs)\n",
    "\n",
    "        loss1 = criterion(outputs1,labels1)\n",
    "        loss2 = criterion(outputs2,labels2)\n",
    "        loss3 = criterion(outputs3,labels3)\n",
    "        loss = (loss1 + loss2 + loss3)/3\n",
    "        \n",
    "        (loss).backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss\n",
    "        \n",
    "        final_outputs.append(torch.cat((outputs1,outputs2,outputs3), dim=1))\n",
    "        final_targets.append(torch.stack((labels1,labels2,labels3), dim=1))\n",
    "    \n",
    "    training_loss = train_loss / int(len(train_dataset)/train_loader.batch_size)\n",
    "    \n",
    "    final_outputs = torch.cat(final_outputs)\n",
    "    final_targets = torch.cat(final_targets)\n",
    "    macro_recall_score = macro_recall(final_outputs, final_targets)\n",
    "    \n",
    "    print('recall score : {:.4f}'.format(macro_recall_score))\n",
    "    print('train loss : {:.4f}'.format(training_loss))\n",
    "    \n",
    "    return macro_recall_score, train_loss, final_outputs, final_targets\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, optimiser, criterion, valid_dataset, valid_loader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        valid_acc = 0.0\n",
    "        valid_loss = 0.0\n",
    "        final_outputs = []\n",
    "        final_targets = []\n",
    "        for idx, (inputs,labels1,labels2,labels3) in tqdm(\n",
    "            enumerate(valid_loader), total=int(len(valid_dataset)/valid_loader.batch_size)):\n",
    "            inputs = inputs.to(device, dtype=torch.float)\n",
    "\n",
    "            labels1 = labels1.to(device, dtype=torch.long)\n",
    "            labels2 = labels2.to(device, dtype=torch.long)\n",
    "            labels3 = labels3.to(device, dtype=torch.long)\n",
    "\n",
    "            outputs1,outputs2,outputs3 = model(inputs)\n",
    "\n",
    "            loss1 = criterion(outputs1,labels1)\n",
    "            loss2 = criterion(outputs2,labels2)\n",
    "            loss3 = criterion(outputs3,labels3)\n",
    "\n",
    "            loss = (loss1+loss2+loss3)/3\n",
    "            valid_loss += loss\n",
    "\n",
    "            final_outputs.append(torch.cat((outputs1,outputs2,outputs3), dim=1))\n",
    "            final_targets.append(torch.stack((labels1,labels2,labels3), dim=1))\n",
    "\n",
    "        \n",
    "        valid_loss = valid_loss / int(len(valid_dataset)/valid_loader.batch_size)\n",
    "        \n",
    "        final_outputs = torch.cat(final_outputs)\n",
    "        final_targets = torch.cat(final_targets)\n",
    "        macro_recall_score = macro_recall(final_outputs, final_targets)\n",
    "        \n",
    "        print('recall score : {:.4f}'.format(macro_recall_score))\n",
    "        print('validation loss : {:.4f}'.format(valid_loss))\n",
    "\n",
    "        return macro_recall_score, valid_loss, final_outputs, final_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def macro_recall(pred_y, y, n_grapheme=168, n_vowel=11, n_consonant=7):\n",
    "    \n",
    "    pred_y = torch.split(pred_y, [n_grapheme, n_vowel, n_consonant], dim=1)\n",
    "    pred_labels = [torch.argmax(py, dim=1).cpu().numpy() for py in pred_y]\n",
    "\n",
    "    y = y.cpu().numpy()\n",
    "\n",
    "    recall_grapheme = metrics.recall_score(pred_labels[0], y[:, 0], average='macro')\n",
    "    recall_vowel = metrics.recall_score(pred_labels[1], y[:, 1], average='macro')\n",
    "    recall_consonant = metrics.recall_score(pred_labels[2], y[:, 2], average='macro')\n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_score = np.average(scores, weights=[2, 1, 1])\n",
    "    print(f'recall: grapheme {recall_grapheme}, vowel {recall_vowel}, consonant {recall_consonant}, 'f'total {final_score}, y {y.shape}')\n",
    "    \n",
    "    return final_score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    use_gpu = True\n",
    "    print(\"Using GPU\")\n",
    "else:\n",
    "    use_gpu = False\n",
    "    \n",
    "FloatTensor = torch.cuda.FloatTensor if use_gpu else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_gpu else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if use_gpu else torch.ByteTensor\n",
    "Tensor = FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "resnet_50 = ResNet50(True).to(device)\n",
    "optimizer = torch.optim.Adam(resnet_50.parameters(), lr=0.00146)\n",
    "#optimizer = torch.optim.SGD(resnet_50.parameters(), lr=4e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n",
    "                                                            mode=\"min\", \n",
    "                                                            patience=5, \n",
    "                                                            factor=0.3,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(resnet_50, (3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accs, train_losses, valid_accs, valid_losses,\\\n",
    "    train_outputs, train_targets, valid_outputs, \\\n",
    "    valid_targets = run_model(resnet_50, optimizer, criterion, \n",
    "                              scheduler, folds=FOLDS, train_batch_size=TRAIN_BATCH_SIZE, validation_batch_size=VALIDATION_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics(train_accs, train_losses, valid_accs, valid_losses, file_name):\n",
    "    # save metrics to csv\n",
    "    new_train_losses = [train_loss.item() for train_loss in train_losses]\n",
    "    new_valid_losses = [valid_loss.item() for valid_loss in valid_losses]\n",
    "    df = [train_accs, new_train_losses, valid_accs, new_valid_losses]\n",
    "    new_df = [*zip(*df)]\n",
    "    dataframe=pd.DataFrame(new_df, \n",
    "                             columns=['train_accs', 'train_losses', 'valid_accs', 'valid_losses'])\n",
    "    dataframe.head()\n",
    "    dataframe.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_metrics(train_accs, train_losses, valid_accs, valid_losses, \"../data/resnet_50_no_pretrained.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_final_confusion_matrices(validation_df, predictions_df):\n",
    "    n_grapheme=168\n",
    "    n_vowel=11\n",
    "    n_consonant=7\n",
    "    \n",
    "    validation_df = torch.split(validation_df, [n_grapheme, n_vowel, n_consonant], dim=1)\n",
    "    validation_df = [torch.argmax(py, dim=1).cpu().numpy() for py in validation_df]\n",
    "    \n",
    "    predictions_df = predictions_df.cpu().numpy()\n",
    "    \n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    #ax1 = fig.add_subplot(311)\n",
    "    ax2 = fig.add_subplot(312)\n",
    "    ax3 = fig.add_subplot(313)\n",
    "    \n",
    "#     commenting because of 168 labels\n",
    "#     cnf_matrix_grapheme_root = metrics.confusion_matrix(validation_df[0], predictions_df[:, 0])\n",
    "#     sn.heatmap(cnf_matrix_grapheme_root, annot=True, linewidths=.5, ax=ax1, fmt='d', cmap=\"Blues\")\n",
    "\n",
    "    cnf_matrix_vowel_diacritic = metrics.confusion_matrix(validation_df[1], predictions_df[:, 1])\n",
    "    sn.heatmap(cnf_matrix_vowel_diacritic, annot=True, linewidths=.5, ax=ax2, fmt='d', cmap=\"Blues\")\n",
    "\n",
    "    cnf_matrix_consonant_diacritic = metrics.confusion_matrix(validation_df[2], predictions_df[:, 2])\n",
    "    sn.heatmap(cnf_matrix_consonant_diacritic, annot=True, linewidths=.5, ax=ax3, fmt='d', cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_final_confusion_matrices(valid_outputs, valid_targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
